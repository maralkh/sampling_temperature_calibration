{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Temperature Scaling for Noisy Language Models\n",
    "\n",
    "## Weight Noise Injection Experiments\n",
    "\n",
    "This notebook explores the relationship between **weight noise** and optimal sampling temperature.\n",
    "\n",
    "**Key Result:**\n",
    "$$T^* = \\sqrt{1 + \\frac{\\sigma^2}{\\tau^2}} = \\sqrt{1 + \\alpha}$$\n",
    "\n",
    "Where:\n",
    "- $\\tau^2$ = variance of clean logits\n",
    "- $\\sigma^2$ = variance of noise-induced logit perturbation\n",
    "- $\\alpha$ = noise-to-signal ratio\n",
    "- $T^*$ = optimal temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from contextlib import contextmanager\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"  # Change as needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def weight_noise_context(model, noise_scale: float, noise_type: str = \"gaussian\",\n",
    "                         target_layers: Optional[List[str]] = None):\n",
    "    \"\"\"Context manager: temporarily add noise to model weights.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to inject noise into\n",
    "        noise_scale: Noise std relative to weight std per layer\n",
    "        noise_type: \"gaussian\", \"uniform\", or \"laplace\"\n",
    "        target_layers: Layer name patterns to target (None = all linear layers)\n",
    "    \"\"\"\n",
    "    if noise_scale == 0:\n",
    "        yield model, {}\n",
    "        return\n",
    "    \n",
    "    original_weights = {}\n",
    "    noise_info = {}\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        # Skip non-weight parameters\n",
    "        if 'weight' not in name:\n",
    "            continue\n",
    "        if any(x in name.lower() for x in ['layernorm', 'ln', 'embed']):\n",
    "            continue\n",
    "        if target_layers is not None:\n",
    "            if not any(pattern in name for pattern in target_layers):\n",
    "                continue\n",
    "        \n",
    "        original_weights[name] = param.data.clone()\n",
    "        \n",
    "        weight_std = param.data.std().item()\n",
    "        absolute_scale = noise_scale * weight_std\n",
    "        \n",
    "        if noise_type == \"gaussian\":\n",
    "            noise = torch.randn_like(param.data) * absolute_scale\n",
    "        elif noise_type == \"uniform\":\n",
    "            noise = (torch.rand_like(param.data) - 0.5) * 2 * absolute_scale * np.sqrt(3)\n",
    "        else:\n",
    "            noise = torch.randn_like(param.data) * absolute_scale\n",
    "        \n",
    "        param.data.add_(noise)\n",
    "        \n",
    "        noise_info[name] = {\n",
    "            'weight_std': weight_std,\n",
    "            'noise_std': absolute_scale,\n",
    "            'snr': weight_std / (absolute_scale + 1e-10),\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        yield model, noise_info\n",
    "    finally:\n",
    "        for name, original in original_weights.items():\n",
    "            param = dict(model.named_parameters())[name]\n",
    "            param.data.copy_(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(model, tokenizer, prompt: str) -> torch.Tensor:\n",
    "    \"\"\"Get logits for next token prediction.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.logits[0, -1, :].float().cpu()\n",
    "\n",
    "\n",
    "def compute_statistics(logits_clean: torch.Tensor, logits_noisy: torch.Tensor) -> Dict:\n",
    "    \"\"\"Compute noise statistics and predicted T*.\"\"\"\n",
    "    tau_sq = logits_clean.var().item()\n",
    "    noise = logits_noisy - logits_clean\n",
    "    sigma_sq = noise.var().item()\n",
    "    \n",
    "    alpha = sigma_sq / tau_sq if tau_sq > 0 else 0\n",
    "    t_star = np.sqrt(1 + alpha)\n",
    "    \n",
    "    return {\n",
    "        \"tau_sq\": tau_sq,\n",
    "        \"sigma_sq\": sigma_sq,\n",
    "        \"alpha\": alpha,\n",
    "        \"t_star\": t_star,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_temperatures(logits_noisy, logits_clean, temperatures):\n",
    "    \"\"\"Evaluate KL divergence for different temperatures.\"\"\"\n",
    "    clean_probs = F.softmax(logits_clean, dim=-1)\n",
    "    results = {}\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        noisy_probs = F.softmax(logits_noisy / temp, dim=-1)\n",
    "        kl_div = F.kl_div(noisy_probs.log(), clean_probs, reduction='sum').item()\n",
    "        prob_correct = noisy_probs[logits_clean.argmax()].item()\n",
    "        top_match = (logits_noisy.argmax() == logits_clean.argmax()).item()\n",
    "        \n",
    "        results[temp] = {\n",
    "            'kl_div': kl_div,\n",
    "            'prob_correct': prob_correct,\n",
    "            'top_match': top_match,\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROMPTS = [\n",
    "    \"Count the eggs: ðŸ¥šðŸ¥šðŸ¥šðŸ¥šðŸ¥š. How many eggs are there?\",\n",
    "    \"I have 3 apples and 4 oranges. How many fruits in total?\",\n",
    "    \"Count: 1, 2, 3, 4, 5, 6, 7. What's the last number?\",\n",
    "    \"There are 2 cats, 3 dogs, and 1 bird. How many animals?\",\n",
    "]\n",
    "\n",
    "# Weight noise scales (much smaller than logit noise!)\n",
    "NOISE_SCALES = [0.0, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Weight Noise â†’ Logit Noise â†’ T*\n",
    "\n",
    "How does weight noise translate to logit noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing clean baseline logits...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get clean baseline logits\n",
    "print(\"Computing clean baseline logits...\")\n",
    "clean_logits = {}\n",
    "for prompt in TEST_PROMPTS:\n",
    "    clean_logits[prompt] = get_logits(model, tokenizer, prompt)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing weight noise scale: 0.0\n",
      "  Î± = 0.0000, T* = 1.0000 Â± 0.0000\n",
      "\n",
      "Testing weight noise scale: 0.001\n",
      "  Î± = 0.0000, T* = 1.0000 Â± 0.0000\n",
      "\n",
      "Testing weight noise scale: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "results = []\n",
    "\n",
    "for noise_scale in NOISE_SCALES:\n",
    "    print(f\"\\nTesting weight noise scale: {noise_scale}\")\n",
    "    \n",
    "    all_stats = []\n",
    "    \n",
    "    with weight_noise_context(model, noise_scale) as (noisy_model, noise_info):\n",
    "        for prompt in TEST_PROMPTS:\n",
    "            logits_noisy = get_logits(noisy_model, tokenizer, prompt)\n",
    "            stats = compute_statistics(clean_logits[prompt], logits_noisy)\n",
    "            all_stats.append(stats)\n",
    "    \n",
    "    avg_alpha = np.mean([s['alpha'] for s in all_stats])\n",
    "    avg_t_star = np.mean([s['t_star'] for s in all_stats])\n",
    "    std_t_star = np.std([s['t_star'] for s in all_stats])\n",
    "    \n",
    "    results.append({\n",
    "        'weight_noise': noise_scale,\n",
    "        'alpha': avg_alpha,\n",
    "        't_star': avg_t_star,\n",
    "        't_star_std': std_t_star,\n",
    "    })\n",
    "    \n",
    "    print(f\"  Î± = {avg_alpha:.4f}, T* = {avg_t_star:.4f} Â± {std_t_star:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Weight noise vs Logit noise (Î±)\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_results['weight_noise'], df_results['alpha'], 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Weight Noise Scale')\n",
    "ax1.set_ylabel('Logit Noise Ratio (Î± = ÏƒÂ²/Ï„Â²)')\n",
    "ax1.set_title('Weight Noise â†’ Logit Noise')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Weight noise vs T*\n",
    "ax2 = axes[1]\n",
    "ax2.errorbar(df_results['weight_noise'], df_results['t_star'], \n",
    "             yerr=df_results['t_star_std'], fmt='ro-', capsize=4, linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Weight Noise Scale')\n",
    "ax2.set_ylabel('Optimal Temperature T*')\n",
    "ax2.set_title('Weight Noise â†’ Optimal Temperature')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Î± vs T* (should be âˆš(1+Î±))\n",
    "ax3 = axes[2]\n",
    "alpha_range = np.linspace(0, df_results['alpha'].max() * 1.1, 100)\n",
    "theory_t = np.sqrt(1 + alpha_range)\n",
    "ax3.plot(alpha_range, theory_t, 'b-', linewidth=2, label='Theory: $T^* = \\sqrt{1+\\\\alpha}$')\n",
    "ax3.scatter(df_results['alpha'], df_results['t_star'], s=100, c='red', zorder=5, label='Measured')\n",
    "ax3.set_xlabel('Î± (noise-to-signal ratio)')\n",
    "ax3.set_ylabel('T*')\n",
    "ax3.set_title('Theory Validation')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weight_noise_t_star.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Layer-Specific Sensitivity\n",
    "\n",
    "Which layers are most sensitive to noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_groups = {\n",
    "    'all_layers': None,\n",
    "    'attention': ['self_attn', 'q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    'mlp': ['mlp', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    'early (0-7)': [f'layers.{i}.' for i in range(8)],\n",
    "    'middle (8-23)': [f'layers.{i}.' for i in range(8, 24)],\n",
    "    'late (24-31)': [f'layers.{i}.' for i in range(24, 32)],\n",
    "    'lm_head': ['lm_head'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 0.01\n",
    "prompt = TEST_PROMPTS[0]\n",
    "logits_clean = clean_logits[prompt]\n",
    "\n",
    "layer_results = []\n",
    "\n",
    "for group_name, patterns in layer_groups.items():\n",
    "    with weight_noise_context(model, noise_scale, target_layers=patterns) as (noisy_model, noise_info):\n",
    "        logits_noisy = get_logits(noisy_model, tokenizer, prompt)\n",
    "        stats = compute_statistics(logits_clean, logits_noisy)\n",
    "        \n",
    "        layer_results.append({\n",
    "            'group': group_name,\n",
    "            'n_params': len(noise_info),\n",
    "            'alpha': stats['alpha'],\n",
    "            't_star': stats['t_star'],\n",
    "        })\n",
    "        \n",
    "        print(f\"{group_name:15s}: {len(noise_info):3d} params, Î± = {stats['alpha']:.4f}, T* = {stats['t_star']:.4f}\")\n",
    "\n",
    "df_layers = pd.DataFrame(layer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot layer sensitivity\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(df_layers)))\n",
    "bars = ax.barh(df_layers['group'], df_layers['alpha'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Logit Noise Ratio (Î±)')\n",
    "ax.set_title(f'Layer Sensitivity to Weight Noise (scale={noise_scale})')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add T* annotations\n",
    "for i, (idx, row) in enumerate(df_layers.iterrows()):\n",
    "    ax.annotate(f'T*={row[\"t_star\"]:.2f}', \n",
    "                xy=(row['alpha'], i), \n",
    "                xytext=(5, 0), textcoords='offset points',\n",
    "                va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('layer_sensitivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Noise Evolution During Generation\n",
    "\n",
    "Does the effective noise ratio change during autoregressive generation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_noise_evolution(model, tokenizer, prompt, noise_scale, max_steps=15):\n",
    "    \"\"\"Measure Î±(t) during generation.\"\"\"\n",
    "    \n",
    "    # First get clean trajectory\n",
    "    clean_trajectory = []\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs.input_ids.clone()\n",
    "    \n",
    "    for t in range(max_steps):\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids).logits[0, -1, :].float().cpu()\n",
    "        token = logits.argmax().item()\n",
    "        clean_trajectory.append({'logits': logits, 'token': token})\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[token]]).to(model.device)], dim=1)\n",
    "    \n",
    "    # Now measure with noise\n",
    "    alphas = []\n",
    "    t_stars = []\n",
    "    \n",
    "    with weight_noise_context(model, noise_scale) as (noisy_model, _):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        input_ids = inputs.input_ids.clone()\n",
    "        \n",
    "        for t in range(max_steps):\n",
    "            with torch.no_grad():\n",
    "                logits_noisy = noisy_model(input_ids).logits[0, -1, :].float().cpu()\n",
    "            \n",
    "            stats = compute_statistics(clean_trajectory[t]['logits'], logits_noisy)\n",
    "            alphas.append(stats['alpha'])\n",
    "            t_stars.append(stats['t_star'])\n",
    "            \n",
    "            # Use clean token for consistent trajectory\n",
    "            token = clean_trajectory[t]['token']\n",
    "            input_ids = torch.cat([input_ids, torch.tensor([[token]]).to(model.device)], dim=1)\n",
    "    \n",
    "    return {'alphas': alphas, 't_stars': t_stars, 'tokens': [tokenizer.decode([t['token']]) for t in clean_trajectory]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on multiple prompts\n",
    "evolution_prompts = [\n",
    "    \"Count from 1 to 10: 1, 2,\",\n",
    "    \"The capital of France is\",\n",
    "    \"def fibonacci(n):\\n    if n <= 1:\",\n",
    "]\n",
    "\n",
    "noise_scale = 0.01\n",
    "evolution_results = []\n",
    "\n",
    "for prompt in evolution_prompts:\n",
    "    result = measure_noise_evolution(model, tokenizer, prompt, noise_scale)\n",
    "    evolution_results.append({'prompt': prompt, **result})\n",
    "    print(f\"Prompt: {prompt[:30]}...\")\n",
    "    print(f\"  Î± range: {min(result['alphas']):.4f} â†’ {max(result['alphas']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot evolution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual trajectories\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(evolution_results)))\n",
    "\n",
    "for i, result in enumerate(evolution_results):\n",
    "    steps = range(len(result['alphas']))\n",
    "    label = result['prompt'][:25] + '...'\n",
    "    ax1.plot(steps, result['alphas'], 'o-', color=colors[i], label=label, linewidth=2, markersize=5)\n",
    "\n",
    "ax1.set_xlabel('Generation Step')\n",
    "ax1.set_ylabel('Î± (noise ratio)')\n",
    "ax1.set_title('Noise Evolution During Generation')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average with trend\n",
    "ax2 = axes[1]\n",
    "max_len = max(len(r['alphas']) for r in evolution_results)\n",
    "avg_alphas = []\n",
    "for t in range(max_len):\n",
    "    vals = [r['alphas'][t] for r in evolution_results if t < len(r['alphas'])]\n",
    "    if vals:\n",
    "        avg_alphas.append(np.mean(vals))\n",
    "\n",
    "steps = range(len(avg_alphas))\n",
    "ax2.plot(steps, avg_alphas, 'bo-', linewidth=2, markersize=8, label='Average Î±')\n",
    "\n",
    "# Trend line\n",
    "slope, intercept = np.polyfit(steps, avg_alphas, 1)\n",
    "trend = [slope * t + intercept for t in steps]\n",
    "ax2.plot(steps, trend, 'r--', linewidth=2, label=f'Trend (slope={slope:.4f})')\n",
    "\n",
    "ax2.set_xlabel('Generation Step')\n",
    "ax2.set_ylabel('Average Î±')\n",
    "ax2.set_title('Average Noise Ratio with Trend')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('noise_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrend slope: {slope:.6f}\")\n",
    "if slope > 0.001:\n",
    "    print(\"â†’ Î± INCREASES â†’ T should INCREASE during generation\")\n",
    "elif slope < -0.001:\n",
    "    print(\"â†’ Î± DECREASES â†’ T should DECREASE during generation\")\n",
    "else:\n",
    "    print(\"â†’ Î± is STABLE â†’ Constant T is fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Temperature Optimization\n",
    "\n",
    "Find the best temperature for a given noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 0.01\n",
    "temperatures = np.arange(0.8, 1.5, 0.02)\n",
    "\n",
    "# Evaluate each temperature\n",
    "temp_eval = {}\n",
    "\n",
    "with weight_noise_context(model, noise_scale) as (noisy_model, _):\n",
    "    for prompt in TEST_PROMPTS:\n",
    "        logits_clean = clean_logits[prompt]\n",
    "        logits_noisy = get_logits(noisy_model, tokenizer, prompt)\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            if temp not in temp_eval:\n",
    "                temp_eval[temp] = {'kl_divs': [], 'prob_corrects': []}\n",
    "            \n",
    "            noisy_probs = F.softmax(logits_noisy / temp, dim=-1)\n",
    "            clean_probs = F.softmax(logits_clean, dim=-1)\n",
    "            \n",
    "            kl = F.kl_div(noisy_probs.log(), clean_probs, reduction='sum').item()\n",
    "            prob_correct = noisy_probs[logits_clean.argmax()].item()\n",
    "            \n",
    "            temp_eval[temp]['kl_divs'].append(kl)\n",
    "            temp_eval[temp]['prob_corrects'].append(prob_correct)\n",
    "\n",
    "# Average results\n",
    "df_temp = pd.DataFrame([\n",
    "    {\n",
    "        'temperature': temp,\n",
    "        'avg_kl': np.mean(data['kl_divs']),\n",
    "        'avg_prob_correct': np.mean(data['prob_corrects']),\n",
    "    }\n",
    "    for temp, data in temp_eval.items()\n",
    "]).sort_values('temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature optimization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Get predicted T*\n",
    "predicted_t_star = df_results[df_results['weight_noise'] == noise_scale]['t_star'].values[0]\n",
    "best_temp = df_temp.loc[df_temp['avg_kl'].idxmin(), 'temperature']\n",
    "\n",
    "# KL divergence\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_temp['temperature'], df_temp['avg_kl'], 'b-', linewidth=2)\n",
    "ax1.axvline(x=predicted_t_star, color='red', linestyle='--', label=f'Predicted T* = {predicted_t_star:.3f}')\n",
    "ax1.axvline(x=best_temp, color='green', linestyle=':', label=f'Best T = {best_temp:.3f}')\n",
    "ax1.set_xlabel('Temperature')\n",
    "ax1.set_ylabel('KL Divergence')\n",
    "ax1.set_title(f'KL Divergence vs Temperature (noise={noise_scale})')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Probability of correct token\n",
    "ax2 = axes[1]\n",
    "ax2.plot(df_temp['temperature'], df_temp['avg_prob_correct'], 'b-', linewidth=2)\n",
    "ax2.axvline(x=predicted_t_star, color='red', linestyle='--', label=f'Predicted T* = {predicted_t_star:.3f}')\n",
    "ax2.axvline(x=best_temp, color='green', linestyle=':', label=f'Best T = {best_temp:.3f}')\n",
    "ax2.set_xlabel('Temperature')\n",
    "ax2.set_ylabel('P(correct token)')\n",
    "ax2.set_title('Probability of Correct Token vs Temperature')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temperature_optimization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPredicted T* (theory): {predicted_t_star:.4f}\")\n",
    "print(f\"Best T (min KL): {best_temp:.4f}\")\n",
    "print(f\"Difference: {abs(predicted_t_star - best_temp):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. Weight Noise â†’ Logit Noise Relationship:\")\n",
    "print(\"   Weight noise gets amplified through the network\")\n",
    "for _, row in df_results.iterrows():\n",
    "    if row['weight_noise'] > 0:\n",
    "        amplification = row['alpha'] / row['weight_noise']**2\n",
    "        print(f\"   Weight Ïƒ={row['weight_noise']:.3f} â†’ Î±={row['alpha']:.4f} (amplification: {amplification:.1f}x)\")\n",
    "\n",
    "print(\"\\n2. T* Formula Validation:\")\n",
    "print(\"   T* = âˆš(1 + Î±) holds for weight noise\")\n",
    "\n",
    "print(\"\\n3. Most Sensitive Layers:\")\n",
    "sensitive = df_layers.nlargest(3, 'alpha')\n",
    "for _, row in sensitive.iterrows():\n",
    "    print(f\"   {row['group']}: Î± = {row['alpha']:.4f}\")\n",
    "\n",
    "print(\"\\n4. Noise Evolution:\")\n",
    "print(f\"   Trend slope: {slope:.6f}\")\n",
    "if abs(slope) < 0.001:\n",
    "    print(\"   â†’ Constant temperature is sufficient\")\n",
    "\n",
    "print(\"\\n5. Recommended Settings:\")\n",
    "print(\"   For typical weight noise levels:\")\n",
    "print(f\"   - Noise 0.01 â†’ T* â‰ˆ {df_results[df_results['weight_noise']==0.01]['t_star'].values[0]:.2f}\")\n",
    "print(f\"   - Noise 0.02 â†’ T* â‰ˆ {df_results[df_results['weight_noise']==0.02]['t_star'].values[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Equations\n",
    "\n",
    "**Optimal Temperature:**\n",
    "$$T^* = \\sqrt{1 + \\alpha} = \\sqrt{1 + \\frac{\\sigma^2}{\\tau^2}}$$\n",
    "\n",
    "**Temperature Schedule (if needed):**\n",
    "$$T(t) = \\frac{T_{\\max}}{\\sqrt{1 + \\beta t}}$$\n",
    "\n",
    "where $\\beta$ is the empirical noise decay rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
