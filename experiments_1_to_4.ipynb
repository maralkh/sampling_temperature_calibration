{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Temperature Scaling for Noisy Language Models\n",
    "\n",
    "**Theory:** For a noisy model with logits z\u0303 = z + \u03b5, the optimal temperature is:\n",
    "\n",
    "$$T^* = \\sqrt{1 + \\alpha}$$\n",
    "\n",
    "where \u03b1 = \u03c3\u00b2_noise / \u03c4\u00b2_signal is the noise-to-signal ratio.\n",
    "\n",
    "**Experiments:**\n",
    "1. Weight noise only\n",
    "2. Activation noise only\n",
    "3. Compare weight vs activation\n",
    "4. Combined noise (additivity test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# UTILITIES - Run this cell first!\n# ============================================================\n\n\"\"\"\nUtility functions for quantization noise and temperature experiments.\n\"\"\"\n\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom contextlib import contextmanager\nimport re\n\n\n# =============================================================================\n# Noise Injection\n# =============================================================================\n\n@contextmanager\ndef weight_noise_context(model, noise_scale):\n    \"\"\"\n    Context manager that adds Gaussian noise to model weights.\n    Noise is removed when exiting the context.\n    \"\"\"\n    original_weights = {}\n    \n    try:\n        # Add noise to weights\n        for name, param in model.named_parameters():\n            if 'weight' in name and param.requires_grad is False:\n                original_weights[name] = param.data.clone()\n                noise = torch.randn_like(param.data) * noise_scale * param.data.std()\n                param.data.add_(noise)\n        \n        yield model, original_weights\n        \n    finally:\n        # Restore original weights\n        for name, param in model.named_parameters():\n            if name in original_weights:\n                param.data.copy_(original_weights[name])\n\n\n@contextmanager  \ndef activation_noise_context(model, noise_scale):\n    \"\"\"\n    Context manager that adds Gaussian noise to activations via forward pre-hooks.\n    Uses INPUT hooks (pre-hook) for realistic quantization simulation.\n    \"\"\"\n    handles = []\n    \n    def make_hook(scale):\n        def hook(module, args, kwargs):\n            if len(args) > 0:\n                x = args[0]\n                noise = torch.randn_like(x) * scale * x.std()\n                noisy_x = x + noise\n                return (noisy_x,) + args[1:], kwargs\n            return args, kwargs\n        return hook\n    \n    try:\n        # Register pre-hooks on linear layers\n        for name, module in model.named_modules():\n            if isinstance(module, torch.nn.Linear):\n                handle = module.register_forward_pre_hook(make_hook(noise_scale), with_kwargs=True)\n                handles.append(handle)\n        \n        yield model, handles\n        \n    finally:\n        # Remove hooks\n        for handle in handles:\n            handle.remove()\n\n\n@contextmanager\ndef combined_noise_context(model, weight_noise_scale, activation_noise_scale):\n    \"\"\"\n    Context manager that adds both weight and activation noise.\n    \"\"\"\n    handles = []\n    original_weights = {}\n    \n    def make_hook(scale):\n        def hook(module, args, kwargs):\n            if len(args) > 0:\n                x = args[0]\n                noise = torch.randn_like(x) * scale * x.std()\n                noisy_x = x + noise\n                return (noisy_x,) + args[1:], kwargs\n            return args, kwargs\n        return hook\n    \n    try:\n        # Add weight noise\n        for name, param in model.named_parameters():\n            if 'weight' in name and param.requires_grad is False:\n                original_weights[name] = param.data.clone()\n                noise = torch.randn_like(param.data) * weight_noise_scale * param.data.std()\n                param.data.add_(noise)\n        \n        # Add activation hooks\n        for name, module in model.named_modules():\n            if isinstance(module, torch.nn.Linear):\n                handle = module.register_forward_pre_hook(make_hook(activation_noise_scale), with_kwargs=True)\n                handles.append(handle)\n        \n        yield model, (original_weights, handles)\n        \n    finally:\n        # Restore weights\n        for name, param in model.named_parameters():\n            if name in original_weights:\n                param.data.copy_(original_weights[name])\n        \n        # Remove hooks\n        for handle in handles:\n            handle.remove()\n\n\n# =============================================================================\n# Alpha (noise-to-signal ratio) Measurement\n# =============================================================================\n\ndef compute_alpha(clean_logits, noisy_logits):\n    \"\"\"\n    Compute noise-to-signal ratio \u03b1 = \u03c3\u00b2_noise / \u03c4\u00b2_signal\n    \n    Args:\n        clean_logits: Logits from clean model\n        noisy_logits: Logits from noisy model\n    \n    Returns:\n        dict with tau_sq, sigma_sq, alpha, t_star\n    \"\"\"\n    diff = noisy_logits - clean_logits\n    tau_sq = clean_logits.var().item()\n    sigma_sq = diff.var().item()\n    alpha = sigma_sq / tau_sq if tau_sq > 0 else 0\n    t_star = np.sqrt(1 + alpha)\n    \n    return {\n        'tau_sq': tau_sq,\n        'sigma_sq': sigma_sq,\n        'alpha': alpha,\n        't_star': t_star\n    }\n\n\ndef get_logits(model, tokenizer, prompt):\n    \"\"\"Get logits for next token prediction.\"\"\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    with torch.no_grad():\n        outputs = model(inputs.input_ids)\n    return outputs.logits[0, -1, :].float()\n\n\n# =============================================================================\n# Generation with Temperature (FIXED - uses sampling!)\n# =============================================================================\n\ndef generate_with_temperature(model, tokenizer, prompt, temperature=1.0, \n                              max_new_tokens=512, do_sample=True, seed=None):\n    \"\"\"\n    Generate text with proper temperature scaling.\n    \n    IMPORTANT: Temperature only affects sampling, not argmax!\n    - do_sample=True: temperature scales probabilities before sampling\n    - do_sample=False: temperature has NO effect (argmax is scale-invariant)\n    \n    Args:\n        model: The language model\n        tokenizer: The tokenizer\n        prompt: Input prompt string\n        temperature: Sampling temperature (only works with do_sample=True)\n        max_new_tokens: Maximum tokens to generate\n        do_sample: If True, sample from distribution. If False, greedy (T ignored!)\n        seed: Random seed for reproducibility\n    \n    Returns:\n        generated_text: The generated string\n        generated_tokens: List of token ids\n    \"\"\"\n    if seed is not None:\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed(seed)\n    \n    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n    input_ids = inputs.input_ids.clone()\n    generated_tokens = []\n    \n    with torch.no_grad():\n        for _ in range(max_new_tokens):\n            outputs = model(input_ids)\n            logits = outputs.logits[0, -1, :].float()\n            \n            if do_sample and temperature > 0:\n                # Apply temperature and sample\n                scaled_logits = logits / temperature\n                probs = F.softmax(scaled_logits, dim=-1)\n                next_token = torch.multinomial(probs, num_samples=1).item()\n            else:\n                # Greedy - temperature has NO effect!\n                next_token = logits.argmax().item()\n            \n            generated_tokens.append(next_token)\n            input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(model.device)], dim=1)\n            \n            if next_token == tokenizer.eos_token_id:\n                break\n    \n    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n    return generated_text, generated_tokens\n\n\ndef generate_greedy(model, tokenizer, prompt, max_new_tokens=512):\n    \"\"\"\n    Generate text with greedy decoding (deterministic).\n    Temperature has NO effect on greedy decoding!\n    \"\"\"\n    return generate_with_temperature(\n        model, tokenizer, prompt, \n        temperature=1.0, max_new_tokens=max_new_tokens, \n        do_sample=False\n    )\n\n\n# =============================================================================\n# Evaluation Metrics\n# =============================================================================\n\ndef evaluate_temperature_effect(clean_logits, noisy_logits, temperatures):\n    \"\"\"\n    Evaluate how different temperatures affect the noisy distribution.\n    \n    For each temperature, computes:\n    - KL divergence from clean distribution\n    - JS divergence (symmetric)\n    - Probability of correct (clean's argmax) token\n    - Cross entropy\n    \n    Args:\n        clean_logits: Logits from clean model\n        noisy_logits: Logits from noisy model  \n        temperatures: List of temperatures to test\n    \n    Returns:\n        dict mapping temperature to metrics\n    \"\"\"\n    clean_probs = F.softmax(clean_logits, dim=-1)\n    correct_token = clean_logits.argmax().item()\n    \n    results = {}\n    \n    for temp in temperatures:\n        noisy_probs = F.softmax(noisy_logits / temp, dim=-1)\n        \n        # KL divergence: KL(clean || noisy)\n        kl_div = F.kl_div(noisy_probs.log(), clean_probs, reduction='sum').item()\n        \n        # JS divergence (symmetric)\n        m_probs = 0.5 * (clean_probs + noisy_probs)\n        js_div = 0.5 * F.kl_div(m_probs.log(), clean_probs, reduction='sum').item() + \\\n                 0.5 * F.kl_div(m_probs.log(), noisy_probs, reduction='sum').item()\n        \n        # Probability of correct token\n        prob_correct = noisy_probs[correct_token].item()\n        \n        # Cross entropy\n        cross_entropy = -(clean_probs * noisy_probs.log()).sum().item()\n        \n        results[temp] = {\n            'kl_div': kl_div,\n            'js_div': js_div,\n            'prob_correct': prob_correct,\n            'cross_entropy': cross_entropy,\n        }\n    \n    return results\n\n\n# =============================================================================\n# GSM8K Helpers\n# =============================================================================\n\ndef extract_answer(text):\n    \"\"\"Extract numerical answer from model output.\"\"\"\n    # Look for #### pattern (GSM8K format)\n    match = re.search(r'####\\s*([\\d,\\.\\-]+)', text)\n    if match:\n        return match.group(1).replace(',', '')\n    \n    # Look for 'answer is X' pattern\n    match = re.search(r'answer is[:\\s]*([\\d,\\.\\-]+)', text.lower())\n    if match:\n        return match.group(1).replace(',', '')\n    \n    # Look for boxed answer (common in reasoning models)\n    match = re.search(r'\\\\boxed\\{([\\d,\\.\\-]+)\\}', text)\n    if match:\n        return match.group(1).replace(',', '')\n    \n    # Look for last number in text\n    numbers = re.findall(r'[\\d,]+\\.?\\d*', text)\n    if numbers:\n        return numbers[-1].replace(',', '')\n    \n    return None\n\n\ndef extract_ground_truth(answer_text):\n    \"\"\"Extract ground truth from GSM8K answer format.\"\"\"\n    match = re.search(r'####\\s*([\\d,\\.\\-]+)', answer_text)\n    if match:\n        return match.group(1).replace(',', '')\n    return None\n\n\ndef check_answer(pred, truth):\n    \"\"\"Check if predicted answer matches ground truth.\"\"\"\n    if pred is None or truth is None:\n        return False\n    try:\n        return abs(float(pred) - float(truth)) < 0.01\n    except:\n        return pred.strip() == truth.strip()\n\n\ndef format_gsm8k_prompt(question, tokenizer, use_chat_template=True):\n    \"\"\"Format GSM8K question as prompt.\"\"\"\n    if use_chat_template and hasattr(tokenizer, 'apply_chat_template'):\n        messages = [\n            {\"role\": \"user\", \"content\": f\"Solve this math problem step by step:\\n{question}\"}\n        ]\n        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    else:\n        return f\"Question: {question}\\nLet me solve this step by step:\\n\"\n\n\n# =============================================================================\n# Reproducibility\n# =============================================================================\n\ndef set_seed(seed):\n    \"\"\"Set random seed for reproducibility.\"\"\"\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\n# =============================================================================\n# Sanity Checks\n# =============================================================================\n\ndef verify_noise_injection(model, tokenizer, noise_ctx_fn, noise_scale, prompt=\"Hello\"):\n    \"\"\"\n    Verify that noise injection is actually working.\n    \n    Returns True if noise is being applied (outputs differ).\n    \"\"\"\n    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n    \n    # Clean output\n    with torch.no_grad():\n        clean_out = model(inputs.input_ids).logits[0, -1, :]\n    \n    # Noisy outputs (should differ each time)\n    noisy_outs = []\n    for _ in range(3):\n        with noise_ctx_fn(model, noise_scale) as (noisy_model, _):\n            with torch.no_grad():\n                noisy_out = noisy_model(inputs.input_ids).logits[0, -1, :]\n                noisy_outs.append(noisy_out.clone())\n    \n    # Check that noisy differs from clean\n    diff_from_clean = (noisy_outs[0] - clean_out).abs().mean().item()\n    \n    # Check that noisy outputs differ from each other (stochastic)\n    diff_between_noisy = (noisy_outs[0] - noisy_outs[1]).abs().mean().item()\n    \n    print(f\"Mean diff from clean: {diff_from_clean:.4f}\")\n    print(f\"Mean diff between noisy runs: {diff_between_noisy:.4f}\")\n    \n    is_working = diff_from_clean > 0.01 and diff_between_noisy > 0.01\n    print(f\"Noise injection working: {is_working}\")\n    \n    return is_working\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"  # Change as needed\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify noise injection\n",
    "print(\"Sanity check - verifying noise injection...\")\n",
    "print(\"\\nWeight noise:\")\n",
    "verify_noise_injection(model, tokenizer, weight_noise_context, 0.05)\n",
    "print(\"\\nActivation noise:\")\n",
    "verify_noise_injection(model, tokenizer, activation_noise_context, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts\n",
    "TEST_PROMPTS = [\n",
    "    \"The capital of France is\",\n",
    "    \"2 + 2 =\",\n",
    "    \"The largest planet in our solar system is\",\n",
    "    \"Water freezes at\",\n",
    "]\n",
    "\n",
    "# Noise scales to test\n",
    "NOISE_SCALES = [0.01, 0.02, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clean baseline logits\n",
    "print(\"Getting clean baseline logits...\")\n",
    "clean_logits = {}\n",
    "for prompt in TEST_PROMPTS:\n",
    "    clean_logits[prompt] = get_logits(model, tokenizer, prompt)\n",
    "print(f\"Got logits for {len(TEST_PROMPTS)} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Weight Noise Only\n",
    "\n",
    "Add Gaussian noise to model weights and measure \u03b1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 1: Weight Noise\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "weight_results = []\n",
    "\n",
    "for noise_scale in NOISE_SCALES:\n",
    "    alphas = []\n",
    "    \n",
    "    for prompt in TEST_PROMPTS:\n",
    "        with weight_noise_context(model, noise_scale) as (noisy_model, _):\n",
    "            noisy_logits = get_logits(noisy_model, tokenizer, prompt)\n",
    "        \n",
    "        result = compute_alpha(clean_logits[prompt], noisy_logits)\n",
    "        alphas.append(result['alpha'])\n",
    "    \n",
    "    mean_alpha = np.mean(alphas)\n",
    "    t_star = np.sqrt(1 + mean_alpha)\n",
    "    \n",
    "    weight_results.append({\n",
    "        'noise_scale': noise_scale,\n",
    "        'alpha': mean_alpha,\n",
    "        't_star': t_star,\n",
    "    })\n",
    "    \n",
    "    print(f\"\u03c3={noise_scale:.3f}: \u03b1={mean_alpha:.4f}, T*={t_star:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Activation Noise Only\n",
    "\n",
    "Add Gaussian noise to activations (at layer inputs) and measure \u03b1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 2: Activation Noise\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "activation_results = []\n",
    "\n",
    "for noise_scale in NOISE_SCALES:\n",
    "    alphas = []\n",
    "    \n",
    "    for prompt in TEST_PROMPTS:\n",
    "        with activation_noise_context(model, noise_scale) as (noisy_model, _):\n",
    "            noisy_logits = get_logits(noisy_model, tokenizer, prompt)\n",
    "        \n",
    "        result = compute_alpha(clean_logits[prompt], noisy_logits)\n",
    "        alphas.append(result['alpha'])\n",
    "    \n",
    "    mean_alpha = np.mean(alphas)\n",
    "    t_star = np.sqrt(1 + mean_alpha)\n",
    "    \n",
    "    activation_results.append({\n",
    "        'noise_scale': noise_scale,\n",
    "        'alpha': mean_alpha,\n",
    "        't_star': t_star,\n",
    "    })\n",
    "    \n",
    "    print(f\"\u03c3={noise_scale:.3f}: \u03b1={mean_alpha:.4f}, T*={t_star:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Compare Weight vs Activation Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 3: Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Noise \u03c3':<10} {'Weight \u03b1':<12} {'Activ \u03b1':<12} {'Ratio':<10} {'Weight T*':<10} {'Activ T*':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for w, a in zip(weight_results, activation_results):\n",
    "    ratio = a['alpha'] / w['alpha'] if w['alpha'] > 0 else float('inf')\n",
    "    print(f\"{w['noise_scale']:<10.3f} {w['alpha']:<12.4f} {a['alpha']:<12.4f} {ratio:<10.1f}x {w['t_star']:<10.4f} {a['t_star']:<10.4f}\")\n",
    "\n",
    "avg_ratio = np.mean([a['alpha']/w['alpha'] for w, a in zip(weight_results, activation_results) if w['alpha'] > 0])\n",
    "print(f\"\\nAverage: Activation noise produces {avg_ratio:.1f}x larger \u03b1 than weight noise!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "noise_scales = [r['noise_scale'] for r in weight_results]\n",
    "weight_alphas = [r['alpha'] for r in weight_results]\n",
    "activ_alphas = [r['alpha'] for r in activation_results]\n",
    "weight_tstars = [r['t_star'] for r in weight_results]\n",
    "activ_tstars = [r['t_star'] for r in activation_results]\n",
    "\n",
    "# Left: \u03b1 vs noise scale\n",
    "ax1 = axes[0]\n",
    "ax1.plot(noise_scales, weight_alphas, 'b-o', label='Weight noise', linewidth=2, markersize=8)\n",
    "ax1.plot(noise_scales, activ_alphas, 'r-s', label='Activation noise', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Noise Scale \u03c3')\n",
    "ax1.set_ylabel('\u03b1 (noise-to-signal ratio)')\n",
    "ax1.set_title('\u03b1 vs Noise Scale')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Right: T* vs noise scale\n",
    "ax2 = axes[1]\n",
    "ax2.plot(noise_scales, weight_tstars, 'b-o', label='Weight noise', linewidth=2, markersize=8)\n",
    "ax2.plot(noise_scales, activ_tstars, 'r-s', label='Activation noise', linewidth=2, markersize=8)\n",
    "ax2.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5, label='T=1')\n",
    "ax2.set_xlabel('Noise Scale \u03c3')\n",
    "ax2.set_ylabel('T* = \u221a(1+\u03b1)')\n",
    "ax2.set_title('Optimal Temperature vs Noise Scale')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weight_vs_activation_noise.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Combined Noise (Additivity Test)\n",
    "\n",
    "Test if \u03b1_combined \u2248 \u03b1_weight + \u03b1_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 4: Noise Additivity\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_noise = 0.05  # Use middle noise level\n",
    "\n",
    "# Get individual \u03b1 values\n",
    "w_result = next(r for r in weight_results if r['noise_scale'] == test_noise)\n",
    "a_result = next(r for r in activation_results if r['noise_scale'] == test_noise)\n",
    "\n",
    "# Measure combined \u03b1\n",
    "combined_alphas = []\n",
    "for prompt in TEST_PROMPTS:\n",
    "    with combined_noise_context(model, test_noise, test_noise) as (noisy_model, _):\n",
    "        noisy_logits = get_logits(noisy_model, tokenizer, prompt)\n",
    "    \n",
    "    result = compute_alpha(clean_logits[prompt], noisy_logits)\n",
    "    combined_alphas.append(result['alpha'])\n",
    "\n",
    "combined_alpha = np.mean(combined_alphas)\n",
    "expected_sum = w_result['alpha'] + a_result['alpha']\n",
    "\n",
    "print(f\"Weight \u03b1:      {w_result['alpha']:.4f}\")\n",
    "print(f\"Activation \u03b1:  {a_result['alpha']:.4f}\")\n",
    "print(f\"Expected sum:  {expected_sum:.4f}\")\n",
    "print(f\"Combined \u03b1:    {combined_alpha:.4f}\")\n",
    "print(f\"Ratio:         {combined_alpha/expected_sum:.2f}x\")\n",
    "\n",
    "if 0.8 < combined_alpha/expected_sum < 1.2:\n",
    "    print(\"\\n\u2713 Noise sources are approximately ADDITIVE!\")\n",
    "else:\n",
    "    print(\"\\n\u2717 Noise sources are NOT additive (interaction effects present)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for additivity\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "categories = ['Weight\\nonly', 'Activation\\nonly', 'Expected\\nsum', 'Combined\\n(actual)']\n",
    "values = [w_result['alpha'], a_result['alpha'], expected_sum, combined_alpha]\n",
    "colors = ['blue', 'red', 'gray', 'purple']\n",
    "\n",
    "bars = ax.bar(categories, values, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('\u03b1 (noise-to-signal ratio)')\n",
    "ax.set_title(f'Noise Additivity Test (\u03c3={test_noise})')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('noise_additivity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: Weight vs Activation Noise\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Noise \u03c3':<10} {'Type':<12} {'\u03b1':<12} {'T*':<10}\")\n",
    "print(\"-\"*44)\n",
    "\n",
    "for w, a in zip(weight_results, activation_results):\n",
    "    print(f\"{w['noise_scale']:<10.3f} {'Weight':<12} {w['alpha']:<12.4f} {w['t_star']:<10.3f}\")\n",
    "    print(f\"{'':<10} {'Activation':<12} {a['alpha']:<12.4f} {a['t_star']:<10.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"1. Activation noise produces ~{avg_ratio:.0f}x larger \u03b1 than weight noise\")\n",
    "print(f\"2. For \u03c3=0.05: Weight T*={weight_results[2]['t_star']:.3f}, Activation T*={activation_results[2]['t_star']:.3f}\")\n",
    "print(f\"3. Noise sources are {'additive' if 0.8 < combined_alpha/expected_sum < 1.2 else 'NOT additive'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "See `experiment_5_temperature.ipynb` for:\n",
    "- Temperature validation with **sampling** (not greedy!)\n",
    "- GSM8K accuracy evaluation\n",
    "- Position-dependent temperature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}