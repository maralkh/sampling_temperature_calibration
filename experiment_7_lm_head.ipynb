{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7: Effective Noise at LM Head\n",
    "\n",
    "**Problem:** LayerNorm, Residual, and Attention modify noise as it propagates through layers.\n",
    "\n",
    "**Solution:** \n",
    "1. Measure \"effective noise\" that reaches the LM Head\n",
    "2. Inject noise directly at LM Head input to test T* without LayerNorm interference\n",
    "\n",
    "**Formula:** $T^* = T_{base} \\cdot \\sqrt{1 + \\alpha}$\n",
    "\n",
    "**Model structure:**\n",
    "```\n",
    "Input → [Layers + LN + Attn + Residual] → Hidden → LM Head → Logits\n",
    "                                            ↑\n",
    "                                    Measure/inject noise here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and utilities loaded!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORTS & UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from contextlib import contextmanager\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ============================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract numerical answer from model response.\"\"\"\n",
    "    # Try boxed format first\n",
    "    boxed = re.findall(r'\\\\boxed\\{([^}]+)\\}', text)\n",
    "    if boxed:\n",
    "        nums = re.findall(r'-?[\\d,]+\\.?\\d*', boxed[-1].replace(',', ''))\n",
    "        if nums:\n",
    "            return nums[-1]\n",
    "    \n",
    "    # Look for patterns like \"answer is X\" or \"= X\"\n",
    "    patterns = [\n",
    "        r'answer is[:\\s]*\\$?(-?[\\d,]+\\.?\\d*)',\n",
    "        r'=\\s*\\$?(-?[\\d,]+\\.?\\d*)\\s*$',\n",
    "        r'\\$(-?[\\d,]+\\.?\\d*)\\s*$',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text.replace(',', ''), re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # Fall back to last number\n",
    "    nums = re.findall(r'-?[\\d,]+\\.?\\d*', text.replace(',', ''))\n",
    "    return nums[-1] if nums else ''\n",
    "\n",
    "def extract_ground_truth(answer_text):\n",
    "    \"\"\"Extract ground truth from GSM8K answer format.\"\"\"\n",
    "    match = re.search(r'####\\s*(-?[\\d,]+\\.?\\d*)', answer_text.replace(',', ''))\n",
    "    return match.group(1) if match else ''\n",
    "\n",
    "def check_answer(pred, truth):\n",
    "    \"\"\"Check if predicted answer matches ground truth.\"\"\"\n",
    "    if not pred or not truth:\n",
    "        return False\n",
    "    try:\n",
    "        return abs(float(pred) - float(truth)) < 1e-5\n",
    "    except:\n",
    "        return pred.strip() == truth.strip()\n",
    "\n",
    "print(\"Imports and utilities loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n",
      "LM Head shape: torch.Size([151936, 1536])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD MODEL\n",
    "# ============================================================\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {model.device}\")\n",
    "print(f\"LM Head shape: {model.lm_head.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM8K loaded: 1319 examples\n",
      "Prepared 10 prompts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD GSM8K\n",
    "# ============================================================\n",
    "\n",
    "gsm8k = load_dataset('gsm8k', 'main', split='test')\n",
    "print(f\"GSM8K loaded: {len(gsm8k)} examples\")\n",
    "\n",
    "# Prepare prompts\n",
    "num_examples = 10\n",
    "test_examples = [gsm8k[i] for i in range(num_examples)]\n",
    "\n",
    "gsm_prompts = []\n",
    "for ex in test_examples:\n",
    "    messages = [{\"role\": \"user\", \"content\": f\"Solve this step by step:\\n{ex['question']}\"}]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    gsm_prompts.append(prompt)\n",
    "\n",
    "print(f\"Prepared {len(gsm_prompts)} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find T_base (Optimal Temperature for Clean Model)\n",
    "\n",
    "Before testing noise, find the optimal temperature for the clean model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FIND T_BASE\n",
    "# ============================================================\n",
    "\n",
    "print(\"Finding T_base (optimal T for clean model)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_temps = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "baseline_results = {}\n",
    "\n",
    "for temp in baseline_temps:\n",
    "    set_seed(SEED)\n",
    "    correct = 0\n",
    "    \n",
    "    for ex in test_examples:\n",
    "        ground_truth = extract_ground_truth(ex['answer'])\n",
    "        messages = [{\"role\": \"user\", \"content\": f\"Solve this step by step:\\n{ex['question']}\"}]\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "        \n",
    "        # Generate with temperature (sampling)\n",
    "        input_ids = inputs.input_ids.clone()\n",
    "        for _ in range(512):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                logits = outputs.logits[0, -1, :].float()\n",
    "            \n",
    "            probs = F.softmax(logits / temp, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            input_ids = torch.cat([input_ids, torch.tensor([[next_token]]).to(model.device)], dim=1)\n",
    "            \n",
    "            if next_token == tokenizer.eos_token_id:\n",
    "                break\n",
    "        \n",
    "        response = tokenizer.decode(input_ids[0, inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        pred = extract_answer(response)\n",
    "        \n",
    "        if check_answer(pred, ground_truth):\n",
    "            correct += 1\n",
    "    \n",
    "    acc = correct / len(test_examples)\n",
    "    baseline_results[temp] = acc\n",
    "    print(f\"T={temp}: {acc:.0%}\")\n",
    "\n",
    "T_base = max(baseline_results.keys(), key=lambda t: baseline_results[t])\n",
    "print(f\"\\n>>> T_base = {T_base} (accuracy: {baseline_results[T_base]:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot T_base results\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "temps = list(baseline_results.keys())\n",
    "accs = [baseline_results[t] for t in temps]\n",
    "\n",
    "ax.plot(temps, accs, 'bo-', linewidth=2, markersize=10)\n",
    "ax.axvline(x=T_base, color='red', linestyle='--', label=f'T_base={T_base}')\n",
    "ax.axvline(x=1.0, color='gray', linestyle=':', alpha=0.5, label='T=1.0')\n",
    "ax.set_xlabel('Temperature')\n",
    "ax.set_ylabel('GSM8K Accuracy')\n",
    "ax.set_title('Clean Model: Finding T_base')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('t_base_optimization.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: LM Head Hooks and Noise Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hooks...\n",
      "Hidden shape: torch.Size([1536])\n",
      "Hidden std: 3.1193\n",
      "Clean logits std: 1.7382\n",
      "Noisy logits std: 1.7523\n",
      "Diff std: 0.2439\n",
      "Hooks working!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# HOOKS FOR CAPTURING HIDDEN STATES\n",
    "# ============================================================\n",
    "\n",
    "class HiddenStateCapture:\n",
    "    \"\"\"Capture hidden states before LM head.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hidden = None\n",
    "        \n",
    "    def hook(self, module, input, output):\n",
    "        self.hidden = input[0].detach().clone()\n",
    "        \n",
    "    def clear(self):\n",
    "        self.hidden = None\n",
    "\n",
    "\n",
    "def get_hidden_before_lm_head(model, tokenizer, prompt):\n",
    "    \"\"\"Get hidden states right before LM head.\"\"\"\n",
    "    capture = HiddenStateCapture()\n",
    "    handle = model.lm_head.register_forward_hook(capture.hook)\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs.input_ids)\n",
    "        return capture.hidden, outputs.logits\n",
    "    finally:\n",
    "        handle.remove()\n",
    "\n",
    "\n",
    "def get_logits_with_head_noise(model, tokenizer, prompt, noise_scale):\n",
    "    \"\"\"\n",
    "    Get logits with noise injected ONLY at LM head input.\n",
    "    Bypasses LayerNorm/Residual effects.\n",
    "    \n",
    "    noise_scale is RELATIVE to hidden std (like activation noise).\n",
    "    \"\"\"\n",
    "    hidden, _ = get_hidden_before_lm_head(model, tokenizer, prompt)\n",
    "    \n",
    "    # Add RELATIVE noise (same as activation_noise_context)\n",
    "    noise = torch.randn_like(hidden) * noise_scale * hidden.std()\n",
    "    noisy_hidden = hidden + noise\n",
    "    \n",
    "    # Apply LM head manually\n",
    "    with torch.no_grad():\n",
    "        noisy_logits = model.lm_head(noisy_hidden)\n",
    "        clean_logits = model.lm_head(hidden)\n",
    "    \n",
    "    return clean_logits[0, -1, :], noisy_logits[0, -1, :], hidden[0, -1, :]\n",
    "\n",
    "\n",
    "# Test\n",
    "print(\"Testing hooks...\")\n",
    "clean_logits, noisy_logits, hidden = get_logits_with_head_noise(model, tokenizer, gsm_prompts[0], noise_scale=0.1)\n",
    "print(f\"Hidden shape: {hidden.shape}\")\n",
    "print(f\"Hidden std: {hidden.std():.4f}\")\n",
    "print(f\"Clean logits std: {clean_logits.std():.4f}\")\n",
    "print(f\"Noisy logits std: {noisy_logits.std():.4f}\")\n",
    "print(f\"Diff std: {(noisy_logits - clean_logits).std():.4f}\")\n",
    "print(\"Hooks working!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Measure Effective Noise at LM Head\n",
    "\n",
    "When noise is injected throughout the model, how much actually reaches the LM head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ACTIVATION NOISE CONTEXT\n",
    "# ============================================================\n",
    "\n",
    "@contextmanager\n",
    "def activation_noise_context(model, noise_scale):\n",
    "    \"\"\"Add noise to activations throughout the model.\"\"\"\n",
    "    handles = []\n",
    "    \n",
    "    def make_hook(scale):\n",
    "        def hook(module, args, kwargs):\n",
    "            if len(args) > 0:\n",
    "                x = args[0]\n",
    "                noise = torch.randn_like(x) * scale * x.std()\n",
    "                noisy_x = x + noise\n",
    "                return (noisy_x,) + args[1:], kwargs\n",
    "            return args, kwargs\n",
    "        return hook\n",
    "    \n",
    "    try:\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                handle = module.register_forward_pre_hook(make_hook(noise_scale), with_kwargs=True)\n",
    "                handles.append(handle)\n",
    "        yield model, handles\n",
    "    finally:\n",
    "        for handle in handles:\n",
    "            handle.remove()\n",
    "\n",
    "\n",
    "def get_hidden_with_noise(model, tokenizer, prompt, noise_scale):\n",
    "    \"\"\"Get hidden states when noise is injected throughout model.\"\"\"\n",
    "    capture = HiddenStateCapture()\n",
    "    handle = model.lm_head.register_forward_hook(capture.hook)\n",
    "    \n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "        with activation_noise_context(model, noise_scale) as (noisy_model, _):\n",
    "            with torch.no_grad():\n",
    "                outputs = noisy_model(inputs.input_ids)\n",
    "        return capture.hidden, outputs.logits\n",
    "    finally:\n",
    "        handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring effective noise at LM head input...\n",
      "======================================================================\n",
      "σ=0.010:\n",
      "  Effective std:  0.3296 ± 0.1409\n",
      "  Effective mean: 0.001380 ± 0.008933\n",
      "  Preservation:   1077.5%\n",
      "σ=0.020:\n",
      "  Effective std:  0.5635 ± 0.1572\n",
      "  Effective mean: 0.004007 ± 0.013124\n",
      "  Preservation:   918.5%\n",
      "σ=0.050:\n",
      "  Effective std:  1.5490 ± 0.5410\n",
      "  Effective mean: 0.008546 ± 0.022395\n",
      "  Preservation:   1006.4%\n",
      "σ=0.100:\n",
      "  Effective std:  2.6211 ± 0.4483\n",
      "  Effective mean: 0.024509 ± 0.043847\n",
      "  Preservation:   851.6%\n",
      "σ=0.200:\n",
      "  Effective std:  3.7051 ± 0.3425\n",
      "  Effective mean: 0.054292 ± 0.046791\n",
      "  Preservation:   601.9%\n",
      "\n",
      "======================================================================\n",
      "Note: If mean ≠ 0, there's a systematic bias in the noise.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MEASURE EFFECTIVE NOISE\n",
    "# ============================================================\n",
    "\n",
    "noise_scales = [0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "print(\"Measuring effective noise at LM head input...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_effective = []\n",
    "\n",
    "for noise_scale in noise_scales:\n",
    "    all_effective_stds = []\n",
    "    all_effective_means = []\n",
    "    all_preservation_ratios = []\n",
    "    \n",
    "    for prompt in gsm_prompts:\n",
    "        # Get clean hidden\n",
    "        clean_hidden, _ = get_hidden_before_lm_head(model, tokenizer, prompt)\n",
    "        clean_h = clean_hidden[0, -1, :]\n",
    "        clean_std = clean_h.std().item()\n",
    "        clean_mean = clean_h.mean().item()\n",
    "        \n",
    "        # Get noisy samples\n",
    "        for _ in range(3):\n",
    "            noisy_hidden, _ = get_hidden_with_noise(model, tokenizer, prompt, noise_scale)\n",
    "            noisy_h = noisy_hidden[0, -1, :]\n",
    "            \n",
    "            diff = noisy_h - clean_h\n",
    "            effective_std = diff.std().item()\n",
    "            effective_mean = diff.mean().item()\n",
    "            \n",
    "            all_effective_stds.append(effective_std)\n",
    "            all_effective_means.append(effective_mean)\n",
    "            \n",
    "            if clean_std > 0:\n",
    "                ratio = effective_std / (noise_scale * clean_std)\n",
    "                all_preservation_ratios.append(ratio)\n",
    "    \n",
    "    mean_std = np.mean(all_effective_stds)\n",
    "    std_std = np.std(all_effective_stds)\n",
    "    mean_mean = np.mean(all_effective_means)\n",
    "    std_mean = np.std(all_effective_means)\n",
    "    mean_ratio = np.mean(all_preservation_ratios)\n",
    "    \n",
    "    results_effective.append({\n",
    "        'noise_scale': noise_scale,\n",
    "        'effective_std_mean': mean_std,\n",
    "        'effective_std_std': std_std,\n",
    "        'effective_mean_mean': mean_mean,\n",
    "        'effective_mean_std': std_mean,\n",
    "        'preservation_ratio': mean_ratio,\n",
    "    })\n",
    "    \n",
    "    print(f\"σ={noise_scale:.3f}:\")\n",
    "    print(f\"  Effective std:  {mean_std:.4f} ± {std_std:.4f}\")\n",
    "    print(f\"  Effective mean: {mean_mean:.6f} ± {std_mean:.6f}\")\n",
    "    print(f\"  Preservation:   {mean_ratio:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Note: If mean ≠ 0, there's a systematic bias in the noise.\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test T* = T_base × √(1+α) with Direct Head Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# T* VALIDATION FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def compute_alpha_at_head(clean_logits, noisy_logits):\n",
    "    \"\"\"Compute α from logits.\"\"\"\n",
    "    diff = noisy_logits - clean_logits\n",
    "    tau_sq = clean_logits.var().item()\n",
    "    sigma_sq = diff.var().item()\n",
    "    alpha = sigma_sq / tau_sq if tau_sq > 0 else 0\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def evaluate_temperature_head_noise(model, tokenizer, prompt, noise_std, temperatures, T_base):\n",
    "    \"\"\"\n",
    "    Evaluate different temperatures with noise injected at LM head.\n",
    "    Uses T_base for clean model comparison.\n",
    "    \"\"\"\n",
    "    clean_logits, noisy_logits, hidden = get_logits_with_head_noise(\n",
    "        model, tokenizer, prompt, noise_std\n",
    "    )\n",
    "    \n",
    "    alpha = compute_alpha_at_head(clean_logits, noisy_logits)\n",
    "    \n",
    "    # Clean probs with T_base (not T=1!)\n",
    "    clean_probs = F.softmax(clean_logits / T_base, dim=-1)\n",
    "    correct_token = (clean_logits / T_base).argmax().item()\n",
    "    \n",
    "    results = {}\n",
    "    for temp in temperatures:\n",
    "        noisy_probs = F.softmax(noisy_logits / temp, dim=-1)\n",
    "        kl_div = F.kl_div(noisy_probs.log(), clean_probs, reduction='sum').item()\n",
    "        prob_correct = noisy_probs[correct_token].item()\n",
    "        \n",
    "        results[temp] = {\n",
    "            'kl_div': kl_div,\n",
    "            'prob_correct': prob_correct,\n",
    "        }\n",
    "    \n",
    "    return alpha, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing T* = T_base × √(1+α) with T_base = 0.8\n",
      "======================================================================\n",
      "Testing temperatures: [0.56, 0.64, 0.72, 0.8, 0.88, 0.96, 1.04, 1.12, 1.2, 1.28, 1.44, 1.6]\n",
      "\n",
      "Noise std: 0.05\n",
      "  α = 0.0058\n",
      "  T* = 0.8 × √(1+0.006) = 0.802\n",
      "  Best T (min KL) = 0.78\n",
      "  Best T (max prob) = 0.56\n",
      "\n",
      "Noise std: 0.075\n",
      "  α = 0.0129\n",
      "  T* = 0.8 × √(1+0.013) = 0.805\n",
      "  Best T (min KL) = 0.78\n",
      "  Best T (max prob) = 0.56\n",
      "\n",
      "Noise std: 0.1\n",
      "  α = 0.0229\n",
      "  T* = 0.8 × √(1+0.023) = 0.809\n",
      "  Best T (min KL) = 0.78\n",
      "  Best T (max prob) = 0.56\n",
      "\n",
      "Noise std: 0.2\n",
      "  α = 0.0926\n",
      "  T* = 0.8 × √(1+0.093) = 0.836\n",
      "  Best T (min KL) = 0.81\n",
      "  Best T (max prob) = 0.58\n",
      "\n",
      "Noise std: 0.5\n",
      "  α = 0.5757\n",
      "  T* = 0.8 × √(1+0.576) = 1.004\n",
      "  Best T (min KL) = 0.96\n",
      "  Best T (max prob) = 0.67\n",
      "\n",
      "Noise std: 0.75\n",
      "  α = 1.3186\n",
      "  T* = 0.8 × √(1+1.319) = 1.218\n",
      "  Best T (min KL) = 1.13\n",
      "  Best T (max prob) = 0.93\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TEST T* WITH T_BASE\n",
    "# ============================================================\n",
    "T_base = 0.8\n",
    "print(f\"Testing T* = T_base × √(1+α) with T_base = {T_base}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "noise_stds = [0.05, 0.075, 0.1, 0.2, 0.5, 0.75]\n",
    "# Temperature range around T_base\n",
    "temperatures = [round(T_base * m, 2) for m in [0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.8, 2.0]]\n",
    "temperatures = sorted(set(temperatures))  # Remove duplicates\n",
    "print(f\"Testing temperatures: {temperatures}\")\n",
    "\n",
    "results_7d = []\n",
    "\n",
    "for noise_std in noise_stds:\n",
    "    print(f\"\\nNoise std: {noise_std}\")\n",
    "    \n",
    "    all_alphas = []\n",
    "    all_best_t_kl = []\n",
    "    all_best_t_prob = []\n",
    "    \n",
    "    for prompt in gsm_prompts:\n",
    "        for _ in range(3):  # Multiple samples\n",
    "            alpha, temp_results = evaluate_temperature_head_noise(\n",
    "                model, tokenizer, prompt, noise_std, temperatures, T_base\n",
    "            )\n",
    "            \n",
    "            best_t_kl = min(temperatures, key=lambda t: temp_results[t]['kl_div'])\n",
    "            best_t_prob = max(temperatures, key=lambda t: temp_results[t]['prob_correct'])\n",
    "            \n",
    "            all_alphas.append(alpha)\n",
    "            all_best_t_kl.append(best_t_kl)\n",
    "            all_best_t_prob.append(best_t_prob)\n",
    "    \n",
    "    mean_alpha = np.mean(all_alphas)\n",
    "    mean_best_t_kl = np.mean(all_best_t_kl)\n",
    "    mean_best_t_prob = np.mean(all_best_t_prob)\n",
    "    \n",
    "    # T* = T_base × √(1+α)\n",
    "    predicted_t_star = T_base * np.sqrt(1 + mean_alpha)\n",
    "    \n",
    "    results_7d.append({\n",
    "        'noise_std': noise_std,\n",
    "        'alpha': mean_alpha,\n",
    "        'predicted_t_star': predicted_t_star,\n",
    "        'best_t_kl': mean_best_t_kl,\n",
    "        'best_t_prob': mean_best_t_prob,\n",
    "    })\n",
    "    \n",
    "    print(f\"  α = {mean_alpha:.4f}\")\n",
    "    print(f\"  T* = {T_base} × √(1+{mean_alpha:.3f}) = {predicted_t_star:.3f}\")\n",
    "    print(f\"  Best T (min KL) = {mean_best_t_kl:.2f}\")\n",
    "    print(f\"  Best T (max prob) = {mean_best_t_prob:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUMMARY TABLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"SUMMARY: T* = T_base × √(1+α) with T_base = {T_base}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Noise σ':<10} {'α':<10} {'T* pred':<10} {'Best T(KL)':<12} {'Best T(prob)':<12} {'Match?'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for r in results_7d:\n",
    "    match = \"✓\" if abs(r['predicted_t_star'] - r['best_t_kl']) < 0.15 else \"✗\"\n",
    "    print(f\"{r['noise_std']:<10.3f} {r['alpha']:<10.4f} {r['predicted_t_star']:<10.3f} \"\n",
    "          f\"{r['best_t_kl']:<12.2f} {r['best_t_prob']:<12.2f} {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT RESULTS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "noise_stds_plot = [r['noise_std'] for r in results_7d]\n",
    "predicted = [r['predicted_t_star'] for r in results_7d]\n",
    "best_kl = [r['best_t_kl'] for r in results_7d]\n",
    "best_prob = [r['best_t_prob'] for r in results_7d]\n",
    "alphas = [r['alpha'] for r in results_7d]\n",
    "\n",
    "# Left: T* comparison\n",
    "ax1 = axes[0]\n",
    "ax1.plot(noise_stds_plot, predicted, 'b-o', linewidth=2, markersize=10, label=f'T* = {T_base}×√(1+α)')\n",
    "ax1.plot(noise_stds_plot, best_kl, 'r--s', linewidth=2, markersize=8, label='Best T (min KL)')\n",
    "ax1.plot(noise_stds_plot, best_prob, 'g--^', linewidth=2, markersize=8, label='Best T (max prob)')\n",
    "ax1.axhline(y=T_base, color='gray', linestyle=':', alpha=0.5, label=f'T_base={T_base}')\n",
    "ax1.set_xlabel('Noise Std at LM Head')\n",
    "ax1.set_ylabel('Temperature')\n",
    "ax1.set_title('Predicted vs Actual Optimal Temperature')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: α vs noise\n",
    "ax2 = axes[1]\n",
    "ax2.plot(noise_stds_plot, alphas, 'bo-', linewidth=2, markersize=10)\n",
    "ax2.set_xlabel('Noise Std at LM Head')\n",
    "ax2.set_ylabel('α (noise-to-signal ratio)')\n",
    "ax2.set_title('α vs Injected Noise')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('t_star_validation_with_tbase.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **T_base found:** Optimal temperature for clean model\n",
    "2. **Effective noise measured:** How much noise survives LayerNorm/Residual\n",
    "3. **T* formula tested:** $T^* = T_{base} \\times \\sqrt{1 + \\alpha}$ with direct head noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
